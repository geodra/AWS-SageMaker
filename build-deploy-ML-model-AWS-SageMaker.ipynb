{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Kaggle Bike Sharing Demand Dataset</h2>\n",
    "\n",
    "Modified 'count' as log1p(count) for training - Log converts a big number to a smaller number.  Once prediction is run, need to reverse this to find actual count by using expm1 function\n",
    "\n",
    "Inspiration: https://www.kaggle.com/apapiu/predicting-bike-sharing-with-xgboost by Alexandru Papiu\n",
    "\n",
    "To download dataset, sign-in and download from this link: https://www.kaggle.com/c/bike-sharing-demand/data\n",
    "\n",
    "Objective: <quote>You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period (Ref: Kaggle.com)</quote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes that the train and test dataset has been uploaded to the SagMaker Jupyter Notebook\n",
    "df = pd.read_csv('train.csv', parse_dates=['datetime'])\n",
    "df_test = pd.read_csv('test.csv', parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert datetime to numeric for training.\n",
    "# Let's extract key features into separate numeric columns\n",
    "def add_features(df):\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "    df['hour'] = df['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features(df)\n",
    "add_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"] = df[\"count\"].map(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Set\n",
    "\n",
    "* Target Variable as first column followed by input features\n",
    "* raining, Validation files do not have a column header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training = 70% of the data\n",
    "# Validation = 30% of the data\n",
    "# Randomize the datset\n",
    "np.random.seed(5)\n",
    "l = list(df.index)\n",
    "np.random.shuffle(l)\n",
    "df = df.iloc[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.shape[0]\n",
    "train = int(.7 * rows)\n",
    "test = int(.3 * rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['count', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed', 'year', 'month', 'day', 'dayofweek','hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Training Set\n",
    "df[:train].to_csv('bike_train.csv'\n",
    "                          ,index=False,header=False\n",
    "                          ,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Validation Set\n",
    "df[train:].to_csv('bike_validation.csv'\n",
    "                          ,index=False,header=False\n",
    "                          ,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data has only input features\n",
    "df_test.to_csv('bike_test.csv'\n",
    "               ,index=False,header=False\n",
    "              ,columns=columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Column List\n",
    "with open('bike_train_column_list.txt','w') as f:\n",
    "    f.write(','.join(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import AWS libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# SageMaker SDK Documentation: http://sagemaker.readthedocs.io/en/latest/estimators.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'georgios-sagemaker'\n",
    "training_file_key = 'biketrain/bike_train.csv'\n",
    "validation_file_key = 'biketrain/bike_validation.csv'\n",
    "test_file_key = 'biketrain/bike_test.csv'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/biketrain/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name,training_file_key)\n",
    "s3_validation_file_location = r's3://{0}/{1}'.format(bucket_name,validation_file_key)\n",
    "s3_test_file_location = r's3://{0}/{1}'.format(bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_validation_file_location)\n",
    "print(s3_test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and Reading from S3 is just as easy\n",
    "# files are referred as objects in S3.  \n",
    "# file name is referred as key name in S3\n",
    "# Files stored in S3 are automatically replicated across 3 different availability zones \n",
    "# in the region where the bucket was created.\n",
    "\n",
    "# http://boto3.readthedocs.io/en/latest/guide/s3.html\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3('bike_train.csv',bucket_name,training_file_key)\n",
    "write_to_s3('bike_validation.csv',bucket_name,validation_file_key)\n",
    "write_to_s3('bike_test.csv',bucket_name,test_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Algorithm Docker Image\n",
    "\n",
    "* AWS Maintains a separate image for every region and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This role contains the permissions needed to train, deploy models\n",
    "# SageMaker Service is trusted to assume this role\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find you region\n",
    "boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access appropriate algorithm container image\n",
    "#  Specify how many instances to use for distributed training and what type of machine to use\n",
    "#  Finally, specify where the trained model artifacts needs to be stored\n",
    "#   Reference: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "#    Optionally, give a name to the training job using base_job_name\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator('813361260812.dkr.ecr.eu-central-1.amazonaws.com/xgboost:latest',\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_model_output_location,\n",
    "                                       sagemaker_session=sess,\n",
    "                                       base_job_name ='xgboost-biketrain-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify hyper parameters that appropriate for the training algorithm\n",
    "# XGBoost Training Parameter Reference: \n",
    "#   https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "\n",
    "# max_depth=5,eta=0.1,subsample=0.7,num_round=150\n",
    "estimator.set_hyperparameters(max_depth=6,objective=\"reg:linear\",\n",
    "                              eta=0.12,subsample=0.73,num_round=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Training Data Location and Optionally, Validation Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content type can be libsvm or csv for XGBoost\n",
    "training_input_config = sagemaker.session.s3_input(s3_data=s3_training_file_location,content_type=\"csv\")\n",
    "validation_input_config = sagemaker.session.s3_input(s3_data=s3_validation_file_location,content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_input_config.config)\n",
    "print(validation_input_config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost supports \"train\", \"validation\" channels\n",
    "# Reference: Supported channels by algorithm\n",
    "#   https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "estimator.fit({'train':training_input_config, 'validation':validation_input_config})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: http://sagemaker.readthedocs.io/en/latest/estimators.html\n",
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m4.xlarge',\n",
    "                             endpoint_name = 'xgboost-biketrain-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict([[3,0,1,2,28.7,33.335,79,12.998,2011,7,7,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensure Training, Test and Validation data are in S3 Bucket\n",
    "* Select Algorithm Container Registry Path - Path varies by region\n",
    "* Configure Estimator for training - Specify Algorithm container, instance count, instance type, model output location\n",
    "* Specify algorithm specific hyper parameters\n",
    "* Train model\n",
    "* Deploy model - Specify instance count, instance type and endpoint name\n",
    "* Run Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
